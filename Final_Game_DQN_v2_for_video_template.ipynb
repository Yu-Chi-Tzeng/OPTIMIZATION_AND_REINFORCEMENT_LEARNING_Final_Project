{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b439967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d59f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # 應該為 True\n",
    "print(torch.version.cuda)         # 應該列出 CUDA 版本\n",
    "print(torch.backends.cudnn.version())  # cuDNN 版本\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d18a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.join(os.getcwd(), 'space_ship_game_RL')\n",
    "if script_dir not in sys.path:\n",
    "    sys.path.append(script_dir)\n",
    "\n",
    "from setting import *\n",
    "from game import Game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1809ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceShipEnv():\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "\n",
    "        # 延後畫面初始化，等 render() 時才設置\n",
    "        self.screen = None\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = FPS\n",
    "\n",
    "        self.game = Game()\n",
    "\n",
    "        self.action_space = [0, 1, 2, 3]\n",
    "        self.observation = self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.game.update(action)\n",
    "    \n",
    "        if self.screen is None:\n",
    "            self.game.draw()\n",
    "        else:\n",
    "            self.game.draw(self.screen)\n",
    "            self.clock.tick(self.fps)\n",
    "    \n",
    "        img_state, structured_state = self.get_state()\n",
    "        state_info = self.game.get_state_info()\n",
    "    \n",
    "        # Components\n",
    "        reward_components = {}\n",
    "    \n",
    "        reward_components['base'] = -0.1  # base survival penalty\n",
    "    \n",
    "        danger_zones = state_info[\"danger_zones\"]  # list of 0/1 flags per zone, length 8\n",
    "        player_speed = abs(self.game.player.sprite.speedx)\n",
    "        rock_density = state_info.get(\"rock_density\", 0)\n",
    "        player_x = self.game.player.sprite.rect.centerx\n",
    "    \n",
    "        zone_id = int(state_info[\"zone_id\"])\n",
    "    \n",
    "        # Safe zone bonus if player zone is not in danger zones\n",
    "        if zone_id not in [i for i, danger in enumerate(danger_zones) if danger]:\n",
    "            reward_components['safe_zone_bonus'] = 0.5\n",
    "        else:\n",
    "            reward_components['safe_zone_bonus'] = 0.0\n",
    "    \n",
    "        # Penalty for being in dangerous zones\n",
    "        reward_components['danger_zone_penalty'] = -0.05 * sum(danger_zones)\n",
    "    \n",
    "        # Encourage movement if danger is present\n",
    "        if sum(danger_zones) > 0 and player_speed > 0.5:\n",
    "            reward_components['movement_bonus'] = 0.2\n",
    "        elif sum(danger_zones) == 0 and player_speed < 0.1:\n",
    "            reward_components['movement_penalty'] = -0.1\n",
    "        else:\n",
    "            reward_components['movement_bonus'] = 0.0\n",
    "            reward_components['movement_penalty'] = 0.0\n",
    "    \n",
    "        # Penalize crowded areas\n",
    "        reward_components['rock_density_penalty'] = -0.3 if rock_density > 3 else 0.0\n",
    "    \n",
    "        # Penalize cornering near edges\n",
    "        reward_components['edge_penalty'] = -0.1 if (player_x < WIDTH * 0.1 or player_x > WIDTH * 0.9) else 0.0\n",
    "    \n",
    "        # Last-minute dodging bonus\n",
    "        if hasattr(self, 'last_zone_danger') and self.last_zone_danger and zone_id not in [i for i, danger in enumerate(danger_zones) if danger]:\n",
    "            reward_components['dodging_bonus'] = 2.0\n",
    "        else:\n",
    "            reward_components['dodging_bonus'] = 0.0\n",
    "        self.last_zone_danger = zone_id in [i for i, danger in enumerate(danger_zones) if danger]\n",
    "    \n",
    "        # Bonuses and penalties from game events\n",
    "        reward_components['hit_rock_bonus'] = 1.0 if self.game.is_hit_rock else 0.0\n",
    "        reward_components['collision_penalty'] = -1.5 if self.game.is_collided else 0.0\n",
    "        reward_components['power_bonus'] = 0.7 if self.game.is_power else 0.0\n",
    "    \n",
    "        # Encourage player to stay below falling powers (lower priority)\n",
    "        power_alignment = any(\n",
    "            abs(power.rect.centerx - player_x) < 40 and\n",
    "            power.rect.bottom > self.game.player.sprite.rect.top - 100\n",
    "            for power in self.game.powers\n",
    "        )\n",
    "        reward_components['power_alignment_bonus'] = 0.3 if power_alignment else 0.0\n",
    "    \n",
    "        # Total reward\n",
    "        reward = sum(reward_components.values())\n",
    "    \n",
    "        next_state = (img_state, structured_state)\n",
    "        done = not self.game.running or self.game.score >= 10000\n",
    "        info = self.game.score\n",
    "    \n",
    "        return next_state, reward, done, info, reward_components\n",
    "        \n",
    "    def reset(self):\n",
    "        self.game = Game()\n",
    "\n",
    "        return self.get_state()\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "            pygame.display.set_caption(\"SpaceShip RL Environment\")\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "    def get_state(self):\n",
    "        raw_frame = self.game.state  # shape: (WIDTH, HEIGHT, 3)\n",
    "        frame = preprocess_frame(raw_frame.swapaxes(0, 1).astype(np.uint8))  # now shape (H, W, 3)\n",
    "        \n",
    "        if not hasattr(self, 'stacked_frames'):\n",
    "            self.stacked_frames = deque([frame]*4, maxlen=4)\n",
    "        else:\n",
    "            self.stacked_frames.append(frame)\n",
    "    \n",
    "        stacked_image = np.stack(self.stacked_frames, axis=0)  # shape: (4, 84, 84)\n",
    "    \n",
    "        # === Structured Features ===\n",
    "        player = self.game.player.sprite\n",
    "        player_x = player.rect.centerx\n",
    "        player_speed = player.speedx\n",
    "        player_zone_id = int(player_x / (WIDTH / 8))\n",
    "    \n",
    "        # --- Danger zones ---\n",
    "        danger_zones = [0] * 8\n",
    "        for rock in self.game.rocks:\n",
    "            if rock.rect.bottom > player.rect.top - 80:  # near the player vertically\n",
    "                zone = int(rock.rect.centerx / (WIDTH / 8))\n",
    "                danger_zones[min(zone, 7)] = 1\n",
    "    \n",
    "        # --- Rock density near player ---\n",
    "        rock_density = sum(\n",
    "            1 for rock in self.game.rocks \n",
    "            if abs(rock.rect.centery - player.rect.centery) < 150\n",
    "        )\n",
    "    \n",
    "        # --- Alignment with falling power ---\n",
    "        power_zone = 0\n",
    "        for power in self.game.powers:\n",
    "            if power.rect.bottom > player.rect.top - 100:\n",
    "                if abs(power.rect.centerx - player_x) < 40:\n",
    "                    power_zone = 1\n",
    "                    break\n",
    "    \n",
    "        # --- Edge proximity flag ---\n",
    "        is_near_edge = 1 if (player_x < WIDTH * 0.1 or player_x > WIDTH * 0.9) else 0\n",
    "    \n",
    "        # --- Last frame zone danger flag ---\n",
    "        last_zone_danger = 0\n",
    "        if hasattr(self, 'last_zone_danger_flag'):\n",
    "            last_zone_danger = int(self.last_zone_danger_flag)\n",
    "    \n",
    "        # Save current danger status for next step\n",
    "        self.last_zone_danger_flag = danger_zones[player_zone_id] == 1\n",
    "    \n",
    "        # --- Construct final structured state ---\n",
    "        structured_state = np.array(\n",
    "            danger_zones +                                 # 8\n",
    "            [player_speed / 10.0,                          # 1 (normalized speed)\n",
    "             rock_density / 10.0,                          # 1 (normalized density)\n",
    "             power_zone,                                   # 1 (under power drop)\n",
    "             player_zone_id / 7.0,                         # 1 (zone ID normalized to 0~1)\n",
    "             is_near_edge,                                 # 1 (edge danger flag)\n",
    "             last_zone_danger],                            # 1 (prior zone danger)\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "        return stacked_image, structured_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf358210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-based DQN Model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_actions, structured_dim=14):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        # === CNN part for image input ===\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)  # (4, 84, 84) → (32, 20, 20)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2) # (64, 9, 9)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1) # (64, 7, 7)\n",
    "        self.flattened_size = 64 * 7 * 7\n",
    "\n",
    "        self.image_fc = nn.Linear(self.flattened_size, 512)\n",
    "\n",
    "        # === MLP for structured input ===\n",
    "        self.structured_fc = nn.Sequential(\n",
    "            nn.Linear(structured_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "\n",
    "        # === Final layers ===\n",
    "        self.combined_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_struct):\n",
    "        # x_img: (B, 4, 84, 84)\n",
    "        x = F.relu(self.conv1(x_img))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.image_fc(x))  # shape: (B, 512)\n",
    "\n",
    "        s = self.structured_fc(x_struct)  # shape: (B, 64)\n",
    "\n",
    "        combined = torch.cat((x, s), dim=1)  # (B, 512 + 64)\n",
    "        return self.combined_fc(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30848ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess frames (grayscale and resize to 84x84)\n",
    "# 預處理影格：轉為灰階並縮放為 84x84\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    # frame: (H, W, 3), dtype should be uint8\n",
    "    if frame.shape[-1] != 3 or frame.dtype != np.uint8:\n",
    "        raise ValueError(f\"Invalid frame shape or dtype: {frame.shape}, {frame.dtype}\")\n",
    "    # frame 是 numpy array (H, W, 3)，先轉為 PIL Image\n",
    "    # Input is a color image (RGB), convert to PIL format for easier processing.\n",
    "    # 輸入是彩色圖像（RGB），轉成 PIL Image 以方便處理。\n",
    "    image = Image.fromarray(frame)\n",
    "\n",
    "    # 轉灰階\n",
    "    # Convert the image to grayscale to reduce input complexity.\n",
    "    # 將影像轉為灰階，降低輸入維度與計算量。\n",
    "    image = image.convert('L')\n",
    "\n",
    "    # resize 成 84x84\n",
    "    # Resize the image to a standard 84x84 shape, as per DQN convention.\n",
    "    # 依照 DQN 的慣例將影像統一縮放至 84x84。\n",
    "    image = image.resize((84, 84), Image.Resampling.BILINEAR)  # or NEAREST, or LANCZOS\n",
    "\n",
    "    # 轉回 numpy 並正規化\n",
    "    # Convert back to NumPy and normalize pixel values to [0, 1].\n",
    "    # 轉回 NumPy 格式並將像素值標準化到 [0, 1]。\n",
    "    frame = np.asarray(image, dtype=np.float32) / 255.0\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # 預處理目前影格\n",
    "    frame = preprocess_frame(state)\n",
    "\n",
    "    if is_new_episode or stacked_frames is None:\n",
    "        # If it's a new episode or no previous frames, initialize with 4 identical frames\n",
    "        # 若是新的一集或是尚未初始化，則用目前影格複製 4 次形成初始堆疊\n",
    "        stacked_frames = deque([frame]*4, maxlen=4)\n",
    "    else:\n",
    "        # 否則把新影格加入到堆疊中，自動捨棄最舊的\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "    # Stack the 4 frames along the first dimension: shape becomes (4, 84, 84)\n",
    "    # 沿著第一維（channel）堆疊成 4 通道輸入：形狀變成 (4, 84, 84)\n",
    "    stacked_state = np.stack(stacked_frames, axis=0)\n",
    "\n",
    "    return stacked_state, stacked_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f81e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_3220\\708265529.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('checkpoint.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (image_fc): Linear(in_features=3136, out_features=512, bias=True)\n",
       "  (structured_fc): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (combined_fc): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions = 4  # Breakout 中的動作數量（例如：無動作、左移、右移、發球）  \n",
    "# Number of possible actions in Breakout (e.g., NOOP, LEFT, RIGHT, FIRE)\n",
    "\n",
    "model = DQN(num_actions, structured_dim=14).to(device)\n",
    "# 建立 DQN 模型並放到指定裝置（CPU 或 GPU）  \n",
    "# Create a DQN model and move it to the specified device (CPU or GPU)\n",
    "\n",
    "checkpoint = torch.load('checkpoint.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['policy_net'])\n",
    "# 載入訓練好的模型權重（可跨裝置載入）  \n",
    "# Load trained model weights (supports device mapping for CPU/GPU compatibility)\n",
    "\n",
    "model.eval()  \n",
    "# 設定模型為評估模式，關閉 dropout/batchnorm 等訓練特性  \n",
    "# Set the model to evaluation mode (disables dropout, batchnorm, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15bcece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -2.45, score: 558\n"
     ]
    }
   ],
   "source": [
    "# Visualization of trained agent\n",
    "env = SpaceShipEnv()\n",
    "env.render()\n",
    "stacked_img, struct = env.reset()  # Already returns (4, 84, 84) and structured vec\n",
    "state = (stacked_img, struct)\n",
    "\n",
    "done = False\n",
    "frames = []\n",
    "\n",
    "while not done:\n",
    "    img_tensor = torch.tensor(state[0], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    struct_tensor = torch.tensor(state[1], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    q_values = model(img_tensor, struct_tensor)\n",
    "    action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "    next_state, reward, done, score, reward_components = env.step(action)\n",
    "    state = next_state  # (stacked_img, struct)\n",
    "\n",
    "    # 把畫面抓下來（RGB）\n",
    "    surface = pygame.display.get_surface()\n",
    "    frame = pygame.surfarray.array3d(surface)  # shape: (W, H, 3)\n",
    "    frame = np.transpose(frame, (1, 0, 2))     # pygame 是 x,y → imageio 是 y,x\n",
    "    frames.append(frame)\n",
    "\n",
    "print(f\"reward: {reward}, score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06fbf4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a2fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 300) to (256, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved gameplay video to: space_ship_run_rl.mp4\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "video_path = \"space_ship_run_rl.mp4\"\n",
    "\n",
    "imageio.mimsave(video_path, frames, fps=60, quality=9)\n",
    "print(f\"Saved gameplay video to: {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (test0)",
   "language": "python",
   "name": "anaconda-test0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
